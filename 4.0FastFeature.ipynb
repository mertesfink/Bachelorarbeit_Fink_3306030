{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe545c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.Dataset import Dataset\n",
    "from src.Evolution import Evolution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "logging.getLogger(\"imported_module\").setLevel(logging.CRITICAL)\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e1a37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Instructions\n",
    "\n",
    "In this notebook feature selection can be carried for the census-income datasets from the UCI repository. This code could be modified to load a different dataset. Four wrapper feature selection methods are used to identify the infromative features using a Decision Tree classifier:\n",
    "\n",
    "* ## CHC$_{QX}$: \n",
    "The hyper-parameter choices of CHC$_{QX}$ are based on the paper “Fast Genetic Algorithm For Feature Selection - A Qualitative Approximation Approach”. The values are set to $q=10$ and $f=10$.\n",
    "\n",
    "* ## PSO$_{QX}$: \n",
    "The hyper-parameter choices of PSO$_{QX}$ are based on the paper “Fast Genetic Algorithm For Feature Selection - A Qualitative Approximation Approach”. The values are set to $q=10$ and $f=10$.\n",
    "\n",
    "* ## CHC: \n",
    "The implementation of a CHC algorithm is according to the paper: “The CHC Adaptive Search Algorithm: How to Have Safe Search When Engaging in Nontraditional Genetic Recombination”. The population size of is 50, the diversity parameter is set to $(d = \\frac{k}{4})$, where $k$ is the length of the individual (number of features), while the divergence rate is $(div = 0.35)$.\n",
    "\n",
    "* ## PSO:\n",
    "The global version of PSO with a topology connecting all particles to one another. The following options are used \\{c1: 1.49618, c2: 1.49618, w: 0.7298\\}, while the number of particles is set to 50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0b0af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CHC$_{QX}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003c699e-24b2-451c-9f1e-b596be5c1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suchzeit Meta-Modell: 371.5473289489746\n",
      "Meta-Modell Bewertung:\n",
      "\n",
      "f_s(g): 0.1675667993177943 = (1 - 0.9999999999999999) + 1179/7036\n",
      "Berechnungszeit: 371.5473289489746 Sekunden\n",
      "Meta-model sample size: 1179\n",
      "Gradient Boosting  75.8045 , Gen =  5 \n"
     ]
    }
   ],
   "source": [
    "#Vorverarbeitete Daten aus CSV auslesen\n",
    "df = pd.read_csv(\"data/df_preprocessed_all.csv\", sep = \",\")\n",
    "df = df.drop(columns=['FELT_LIFE','REMOVAL_DATE', 'INSTALLATION_DATE', 'REPORT_DATE'])\n",
    "\n",
    "#Das Label nennen\n",
    "label = df.columns.get_loc('FELT_LIFE_NET')\n",
    "\n",
    "#Machine Learning Algorithms die benutzt werden\n",
    "MLA = [\n",
    "    #('Linear Regressor',LinearRegression()),\n",
    "   #('SVR', SVR()),\n",
    "    #('Random Forest',RandomForestRegressor()),\n",
    "    ('Gradient Boosting', xgb.XGBRegressor())\n",
    "]\n",
    "\n",
    "results_chcqx = {}\n",
    "predictions_chcqx = {}\n",
    "header = df.columns\n",
    "\n",
    "\n",
    "population_size = 20\n",
    "\n",
    "\n",
    "# Für alle Modelle in MLA FS mit CHCqx mit anschließender Validierung\n",
    "for model_name, model_instance in MLA:\n",
    "    \n",
    "    dataset = Dataset(df, 'df', label, divide_dataset=False, header=header)\n",
    "\n",
    "    dataset.divide_dataset(model_instance, normalize=False, shuffle=True, all_features=True, all_instances=True, evaluate=False, partial_sample=False,folds=5)\n",
    "    \n",
    "    #FS mit Approximation des CHC\n",
    "    ind_size = dataset.X_train.shape[1]\n",
    "    meta_dict, log, baseline_full_data = Evolution.CHCqx(dataset, 5, 5, 2, population_size, verbose=1)\n",
    "    feature_subset = log.iloc[-1]['ind']\n",
    "    feature_subset = np.array(feature_subset)\n",
    "    \n",
    "    selected_features = list(np.where(feature_subset == 1)[0])\n",
    "    num_selected_features = len(selected_features)\n",
    "    duration = np.round(log.iloc[-1]['time'], 2)\n",
    "    \n",
    "    dataset.set_features(selected_features)\n",
    "    \n",
    "    #Regressor trainieren\n",
    "    dataset.fit_classifier()\n",
    "    \n",
    "    # Cross-Validation\n",
    "    dataset.set_CV()\n",
    "    cv = dataset.get_CV()\n",
    "    \n",
    "    #Validierung auf Testset\n",
    "    dataset.set_train_metrics()\n",
    "    train = dataset.get_train_metrics()\n",
    "    traintime = dataset.get_traintime()\n",
    "    \n",
    "    \n",
    "    dataset.set_test_metrics()\n",
    "    test = dataset.get_test_metrics()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    results_chcqx[model_name] = {\n",
    "        'Model_name': model_name,\n",
    "        'CV_TrainMAE': cv['CV_TrainMAE'],\n",
    "        'CV_TrainRMSE': cv['CV_TrainRMSE'],\n",
    "        'CV_TestMAE': cv['CV_TestMAE'],\n",
    "        'CV_TestRMSE': cv['CV_TestRMSE'],\n",
    "        'CV_fit_time': cv['CV_fit_time'],\n",
    "        'CV_fit_time_ges':cv['CV_fit_time']+duration,\n",
    "        'TrainRMSE': train['TrainRMSE'],\n",
    "        'TrainMAE': train['TrainMAE'],\n",
    "        'TestRMSE': test['TestRMSE'],\n",
    "        'TestMAE': test['TestMAE'],\n",
    "        'TrainTime': traintime,\n",
    "        'TrainTime_ges': traintime+duration,\n",
    "        'Features': selected_features,\n",
    "        'Feature-Anzahl': num_selected_features,\n",
    "        'FS-Laufzeit': duration,\n",
    "        'Meta-Modell-Zeit': meta_dict['meta_model_time'],\n",
    "        'Spearman-Rangkoeffizient Meta-Modell': meta_dict['coef'],\n",
    "        'Sample_size': meta_dict['sample_size'],\n",
    "        'Full_sample_size': meta_dict['full_sample_size'],\n",
    "        'F_s(g)': meta_dict['f_s(g)']\n",
    "    }\n",
    "    \n",
    "    predictions_chcqx[model_name] = {\n",
    "    'Model_name': model_name,\n",
    "    'y_train': dataset.get_y_train(),\n",
    "    'y_test': dataset.get_y_test(),\n",
    "    'pred_train': dataset.get_y_pred_train(),\n",
    "    'pred_test':dataset.get_y_pred_test()\n",
    "    }\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57620a6a-1093-4069-b33a-8cebc29f6460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Speichern der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd87975-445a-49e3-a903-fc23ff101566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chcqx = pd.DataFrame(results_chcqx)\n",
    "df_chcqx = df_chcqx.transpose()\n",
    "df_chcqx.to_csv('data/CHCqx/All_FS_chcqx_metrics.csv', index=False)\n",
    "\n",
    "# Features der chcqx speichern\n",
    "df_features_chcqx = pd.DataFrame()\n",
    "# Maximale Anzahl von ausgewählten Features über alle Modelle bestimmen\n",
    "max_selected_features = max(len(results_chcqx[model_name]['Features']) for model_name, _ in MLA)\n",
    "\n",
    "# Iteration über die Modelle und Hinzufügen der Feature-Namen in df_features_chcqx\n",
    "for model_name, model_instance in MLA:\n",
    "    selected_features = df.columns[results_chcqx[model_name]['Features']]\n",
    "    \n",
    "    # Auffüllen der nicht ausgewählten Features mit NaN\n",
    "    if len(selected_features) < max_selected_features:\n",
    "        selected_features = np.append(selected_features, [np.nan] * (max_selected_features - len(selected_features)))\n",
    "    \n",
    "    # Die ausgewählten Spaltennamen in eine neue Spalte in df_features_chcqx einfügen\n",
    "    df_features_chcqx[model_name] = selected_features\n",
    "\n",
    "df_features_chcqx.to_csv('data/CHCqx/All_FS_chcqx_Features.csv', index=False)\n",
    "\n",
    "#Predictions speichern\n",
    "chcqx_data = []\n",
    "# Iteriere über die Modelle und ihre Daten\n",
    "for model_name, data in predictions_chcqx.items():\n",
    "    model_data = data.copy()\n",
    "    model_data.pop('Model_name')  # Entferne den Eintrag 'Model_name'\n",
    "    for data_type, values in model_data.items():\n",
    "        # Iteriere über die Werte in jedem Datenfeld und füge sie zur flattened_data-Liste hinzu\n",
    "        for value in values:\n",
    "            chcqx_data.append({'Model_name': model_name, 'Data_type': data_type, 'Value': value})\n",
    "\n",
    "\n",
    "df_chcqx2 = pd.DataFrame(chcqx_data)\n",
    "df_chcqx2.to_csv('data/CHCqx/All_FS_chcqx_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffcfbb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PSO$_{QX}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cf5c51-df4f-4030-8767-634f8b3eabf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suchzeit Meta-Modell: 883.6395637989044\n",
      "Meta-Modell Bewertung:\n",
      "\n",
      "f_s(g): 0.1675667993177943 = (1 - 0.9999999999999999) + 1179/7036\n",
      "Berechnungszeit: 883.6395637989044 Sekunden\n",
      "Meta-model sample size: 1179\n",
      "Finished: Model Gradient Boosting, Iteration: 1\n",
      "Alle Iterationen abgeschlossen und Ergebnisse gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Vorverarbeitete Daten aus CSV auslesen\n",
    "df = pd.read_csv(\"data/df_preprocessed_all.csv\", sep=\",\")\n",
    "df = df.drop(columns=['FELT_LIFE','REMOVAL_DATE', 'INSTALLATION_DATE', 'REPORT_DATE'])\n",
    "\n",
    "# Das Label nennen\n",
    "label = df.columns.get_loc('FELT_LIFE_NET')\n",
    "\n",
    "# Machine Learning Algorithms die benutzt werden\n",
    "MLA = [\n",
    "    #('Linear Regressor', LinearRegression()),\n",
    "    #('SVR', SVR()),\n",
    "    #('Random Forest',RandomForestRegressor()),\n",
    "    ('Gradient Boosting', xgb.XGBRegressor())\n",
    "]\n",
    "\n",
    "# PSOqx-Optionen\n",
    "population_size = 20\n",
    "options = {'c1': 2, 'c2': 2, 'w': 0.6, 'k': population_size, 'p':2}\n",
    "\n",
    "# Anzahl der Durchläufe\n",
    "num_iterations = 1\n",
    "\n",
    "# Ergebnisse über alle Iterationen speichern\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    results_psoqx = {}\n",
    "    predictions_psoqx = {}\n",
    "    header = df.columns\n",
    "    \n",
    "    # Für alle Modelle in MLA FS mit PSOqx mit anschließender Validierung\n",
    "    for model_name, model_instance in MLA:\n",
    "        \n",
    "        dataset = Dataset(df, 'df', label, divide_dataset=False, header=header)\n",
    "        dataset.divide_dataset(model_instance, normalize=False, shuffle=True, all_features=True, all_instances=True, evaluate=False, partial_sample=False, folds=5)\n",
    "        \n",
    "        # FS mit Approximation des PSOqx\n",
    "        ind_size = dataset.X_train.shape[1]\n",
    "        meta_dict, log, baseline_full_data = Evolution.PSOqx(dataset, options, f=5, n_individual=5, f_no_change=2, n_particles=population_size, verbose=1)\n",
    "        \n",
    "        feature_subset = log.iloc[-1]['ind']\n",
    "        feature_subset = np.array(feature_subset)\n",
    "        \n",
    "        selected_features = list(np.where(feature_subset == 1)[0])\n",
    "        num_selected_features = len(selected_features)\n",
    "        duration = np.round(log.iloc[-1]['time'], 2)\n",
    "        \n",
    "        dataset.set_features(selected_features)\n",
    "        \n",
    "        # Regressor trainieren\n",
    "        dataset.fit_classifier()\n",
    "        \n",
    "        # Cross-Validation\n",
    "        dataset.set_CV()\n",
    "        cv = dataset.get_CV()\n",
    "        \n",
    "        # Validierung auf Testset\n",
    "        dataset.set_train_metrics()\n",
    "        train = dataset.get_train_metrics()\n",
    "        traintime = dataset.get_traintime()\n",
    "        \n",
    "        \n",
    "        dataset.set_test_metrics()\n",
    "        test = dataset.get_test_metrics()\n",
    "        \n",
    "        # Ergebnisse speichern\n",
    "        results_psoqx[model_name] = {\n",
    "            'Model_name': model_name,\n",
    "            'CV_TrainMAE': cv['CV_TrainMAE'],\n",
    "            'CV_TrainRMSE': cv['CV_TrainRMSE'],\n",
    "            'CV_TestMAE': cv['CV_TestMAE'],\n",
    "            'CV_TestRMSE': cv['CV_TestRMSE'],\n",
    "            'CV_fit_time': cv['CV_fit_time'],\n",
    "            'CV_fit_time_ges': cv['CV_fit_time'] + duration,\n",
    "            'TrainRMSE': train['TrainRMSE'],\n",
    "            'TrainMAE': train['TrainMAE'],\n",
    "            'TestRMSE': test['TestRMSE'],\n",
    "            'TestMAE': test['TestMAE'],\n",
    "            'TrainTime': traintime,\n",
    "            'TrainTime_ges': traintime + duration,\n",
    "            'Features': selected_features,\n",
    "            'Feature-Anzahl': num_selected_features,\n",
    "            'FS-Laufzeit': duration,\n",
    "            'Meta-Modell-Zeit': meta_dict['meta_model_time'],\n",
    "            'Spearman-Rangkoeffizient Meta-Modell': meta_dict['coef'],\n",
    "            'Sample_size': meta_dict['sample_size'],\n",
    "            'Full_sample_size': meta_dict['full_sample_size'],\n",
    "            'F_s(g)': meta_dict['f_s(g)']\n",
    "        }\n",
    "        \n",
    "        predictions_psoqx[model_name] = {\n",
    "            'Model_name': model_name,\n",
    "            'y_train': dataset.get_y_train(),\n",
    "            'y_test': dataset.get_y_test(),\n",
    "            'pred_train': dataset.get_y_pred_train(),\n",
    "            'pred_test': dataset.get_y_pred_test()\n",
    "        }\n",
    "        \n",
    "        print(f\"Finished: Model {model_name}, Iteration: {iteration}\")\n",
    "    \n",
    "    # Ergebnisse der aktuellen Iteration in DataFrames umwandeln\n",
    "    df_psoqx = pd.DataFrame(results_psoqx).transpose()\n",
    "    df_psoqx.to_csv(f'data/PSOqx/{iteration:02d}_All_FS_psoqx_metrics.csv', index=False)\n",
    "    \n",
    "    # Features der aktuellen Iteration speichern\n",
    "    df_features_psoqx = pd.DataFrame()\n",
    "    max_selected_features = max(len(results_psoqx[model_name]['Features']) for model_name, _ in MLA)\n",
    "    for model_name, model_instance in MLA:\n",
    "        selected_features = df.columns[results_psoqx[model_name]['Features']]\n",
    "        if len(selected_features) < max_selected_features:\n",
    "            selected_features = np.append(selected_features, [np.nan] * (max_selected_features - len(selected_features)))\n",
    "        df_features_psoqx[model_name] = selected_features\n",
    "    df_features_psoqx.to_csv(f'data/PSOqx/{iteration:02d}_All_FS_psoqx_Features.csv', index=False)\n",
    "    \n",
    "    # Predictions speichern\n",
    "    psoqx_data = []\n",
    "    for model_name, data in predictions_psoqx.items():\n",
    "        model_data = data.copy()\n",
    "        model_data.pop('Model_name')\n",
    "        for data_type, values in model_data.items():\n",
    "            for value in values:\n",
    "                psoqx_data.append({'Model_name': model_name, 'Data_type': data_type, 'Value': value})\n",
    "    df_psoqx2 = pd.DataFrame(psoqx_data)\n",
    "    df_psoqx2.to_csv(f'data/PSOqx/{iteration:02d}_All_FS_psoqx_predictions.csv', index=False)\n",
    "\n",
    "print(\"Alle Iterationen abgeschlossen und Ergebnisse gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0245fad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b131134-6d9b-4796-99c0-17223f4ebd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Model Gradient Boosting=  2 \n",
      "Finished: Iteration: 1\n",
      "Finished: Model Gradient Boosting=  3 \n",
      "Finished: Iteration: 2\n",
      "Finished: Model Gradient Boosting=  2 \n",
      "Finished: Iteration: 3\n",
      "Finished: Model Gradient Boosting=  2 \n",
      "Finished: Iteration: 4\n",
      "Finished: Model Gradient Boosting=  2 \n",
      "Finished: Iteration: 5\n",
      "Alle Iterationen abeschlossen und Ergebnisse gespeichert.\n"
     ]
    }
   ],
   "source": [
    "#Vorverarbeitete Daten aus CSV auslesen\n",
    "df = pd.read_csv(\"data/df_preprocessed_all.csv\", sep = \",\")\n",
    "df = df.drop(columns=['FELT_LIFE','REMOVAL_DATE', 'INSTALLATION_DATE', 'REPORT_DATE'])\n",
    "\n",
    "#Das Label nennen\n",
    "label = df.columns.get_loc('FELT_LIFE_NET')\n",
    "\n",
    "#Machine Learning Algorithms die benutzt werden\n",
    "MLA = [\n",
    "    #('Linear Regressor',LinearRegression()),\n",
    "    #('SVR', SVR(kernel='linear')),\n",
    "    #('Random Forest',RandomForestRegressor()),\n",
    "    ('Gradient Boosting', xgb.XGBRegressor())\n",
    "]\n",
    "\n",
    "\n",
    "evaluation = ['train', 'cv_train', 'cv_test', 'validation', 'test']\n",
    "header = df.columns\n",
    "task = 'feature_selection'\n",
    "target_dataset = 'validation'\n",
    "\n",
    "# Anzahl der Durchläufe\n",
    "num_iterations = 5\n",
    "\n",
    "population_size = 20\n",
    "\n",
    "# Ergebnisse über alle Iterationen speichern\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    results_chc = {}\n",
    "    predictions_chc = {}\n",
    "    header = df.columns\n",
    "    \n",
    "    # Für alle Modelle in MLA FS mit chc mit anschließender Validierung\n",
    "    for model_name, model_instance in MLA:\n",
    "\n",
    "        dataset = Dataset(df, 'df', label, divide_dataset=False, header=header)\n",
    "\n",
    "        dataset.divide_dataset(model_instance, normalize=False, shuffle=True, all_features=True, all_instances=True, evaluate=False, partial_sample=False,folds=5)\n",
    "\n",
    "        #FS mit Approximation des CHC\n",
    "        ind_size = dataset.X_train.shape[1]\n",
    "        toolbox = Evolution.create_toolbox(task, target_dataset, dataset, dataset)\n",
    "        population = Evolution.create_population(population_size, ind_size)\n",
    "        d = ind_size // 4\n",
    "\n",
    "        log, population, d, FS_time = Evolution.CHC(dataset, toolbox, d, population, verbose=1, max_no_change=2, max_generations=5)\n",
    "        feature_subset = log.iloc[-1]['best_solution']  \n",
    "        feature_subset = np.array(feature_subset)\n",
    "\n",
    "        selected_features = list(np.where(feature_subset == 1)[0])\n",
    "        num_selected_features = len(selected_features)\n",
    "        duration = np.round(log.iloc[-1]['time'], 2)\n",
    "\n",
    "\n",
    "        dataset.set_features(selected_features)\n",
    "\n",
    "        #Regressor trainieren\n",
    "        dataset.fit_classifier()\n",
    "\n",
    "        # Cross-Validation\n",
    "        dataset.set_CV()\n",
    "        cv = dataset.get_CV()\n",
    "\n",
    "        #Validierung auf Validation- und Testset\n",
    "        dataset.set_train_metrics()\n",
    "        train = dataset.get_train_metrics()\n",
    "        traintime = dataset.get_traintime()\n",
    "\n",
    "\n",
    "        dataset.set_test_metrics()\n",
    "        test = dataset.get_test_metrics()\n",
    "\n",
    "\n",
    "\n",
    "        #dataset.plot_shapley_values(\"FS_corr_\"+model_name)\n",
    "\n",
    "        results_chc[model_name] = {\n",
    "            'Model_name': model_name,\n",
    "            'CV_TrainMAE': cv['CV_TrainMAE'],\n",
    "            'CV_TrainRMSE': cv['CV_TrainRMSE'],\n",
    "            'CV_TestMAE': cv['CV_TestMAE'],\n",
    "            'CV_TestRMSE': cv['CV_TestRMSE'],\n",
    "            'CV_fit_time': cv['CV_fit_time'],\n",
    "            'CV_fit_time_ges':cv['CV_fit_time']+duration,\n",
    "            'TrainRMSE': train['TrainRMSE'],\n",
    "            'TrainMAE': train['TrainMAE'],\n",
    "            'TestRMSE': test['TestRMSE'],\n",
    "            'TestMAE': test['TestMAE'],\n",
    "            'TrainTime': traintime,\n",
    "            'TrainTime_ges': traintime+FS_time,\n",
    "            'Features': selected_features,\n",
    "            'Feature-Anzahl': num_selected_features,\n",
    "            'FS-Laufzeit': FS_time\n",
    "        }\n",
    "\n",
    "        predictions_chc[model_name] = {\n",
    "        'Model_name': model_name,\n",
    "        'y_train': dataset.get_y_train(),\n",
    "        'y_test': dataset.get_y_test(),\n",
    "        'pred_train': dataset.get_y_pred_train(),\n",
    "        'pred_test':dataset.get_y_pred_test()\n",
    "        }\n",
    "        print(f\"Finished: Model {model_name}\")\n",
    "\n",
    "    # Ergebnisse der aktuellen Iteration in DataFrames umwandeln\n",
    "    df_chc = pd.DataFrame(results_chc).transpose()\n",
    "    df_chc.to_csv(f'data/CHC/{iteration:02d}_FS_chc_metrics.csv', index=False)\n",
    "    \n",
    "    # Features der aktuellen Iteration speichern\n",
    "    df_features_chc = pd.DataFrame()\n",
    "    max_selected_features = max(len(results_chc[model_name]['Features']) for model_name, _ in MLA)\n",
    "    for model_name, model_instance in MLA:\n",
    "        selected_features = df.columns[results_chc[model_name]['Features']]\n",
    "        if len(selected_features) < max_selected_features:\n",
    "            selected_features = np.append(selected_features, [np.nan] * (max_selected_features - len(selected_features)))\n",
    "        df_features_chc[model_name] = selected_features\n",
    "    df_features_chc.to_csv(f'data/CHC/{iteration:02d}_FS_chc_Features.csv', index=False)\n",
    "    \n",
    "    # Predictions speichern\n",
    "    chc_data = []\n",
    "    for model_name, data in predictions_chc.items():\n",
    "        model_data = data.copy()\n",
    "        model_data.pop('Model_name')\n",
    "        for data_type, values in model_data.items():\n",
    "            for value in values:\n",
    "                chc_data.append({'Model_name': model_name, 'Data_type': data_type, 'Value': value})\n",
    "    df_chc2 = pd.DataFrame(chc_data)\n",
    "    df_chc2.to_csv(f'data/CHC/{iteration:02d}_FS_chc_predictions.csv', index=False)\n",
    "\n",
    "    print(f\"Finished: Iteration: {iteration}\")\n",
    "\n",
    "print(\"Alle Iterationen abeschlossen und Ergebnisse gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0aa554",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6356cf-c227-4b93-8f1a-af669ec0d10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 1\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 2\n",
      "Finished: Model: Gradient Boosting=  3 \n",
      "Finished: Iteration: 3\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 4\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 5\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 6\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 7\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 8\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 9\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 10\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 11\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 12\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 13\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 14\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 15\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 16\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 17\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 18\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 19\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 20\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 21\n",
      "Finished: Model: Gradient Boosting =  3 \n",
      "Finished: Iteration: 22\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 23\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 24\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 25\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 26\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 27\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 28\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 29\n",
      "Finished: Model: Gradient Boosting =  5 \n",
      "Finished: Iteration: 30\n"
     ]
    }
   ],
   "source": [
    "from pyswarms.backend.topology import Ring\n",
    "from pyswarms.backend.topology import Star\n",
    "\n",
    "#Vorverarbeitete Daten aus CSV auslesen\n",
    "df = pd.read_csv(\"data/df_preprocessed_all.csv\", sep = \",\")\n",
    "df = df.drop(columns=['FELT_LIFE','REMOVAL_DATE', 'INSTALLATION_DATE', 'REPORT_DATE'])\n",
    "\n",
    "#Das Label nennen\n",
    "label = df.columns.get_loc('FELT_LIFE_NET')\n",
    "\n",
    "#Machine Learning Algorithms die benutzt werden\n",
    "MLA = [\n",
    "    #('Linear Regressor',LinearRegression()),\n",
    "    #('SVR', SVR(kernel='linear')),\n",
    "    #('Random Forest',RandomForestRegressor()),\n",
    "    ('Gradient Boosting', xgb.XGBRegressor())\n",
    "]\n",
    "\n",
    "header = df.columns\n",
    "\n",
    "\n",
    "population_size = 20\n",
    "options = {'c1': 2, 'c2': 2, 'w': 0.6, 'k': population_size, 'p':2}\n",
    "topology = Star()\n",
    "\n",
    "# Anzahl der Durchläufe\n",
    "num_iterations = 30\n",
    "\n",
    "# Ergebnisse über alle Iterationen speichern\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    results_pso = {}\n",
    "    predictions_pso = {}\n",
    "    header = df.columns\n",
    "    \n",
    "    # Für alle Modelle in MLA FS mit PSO mit anschließender Validierung\n",
    "    for model_name, model_instance in MLA:\n",
    "\n",
    "        dataset = Dataset(df, 'df', label, divide_dataset=False, header=header)\n",
    "\n",
    "        dataset.divide_dataset(model_instance, normalize=False, shuffle=True, all_features=True, all_instances=True, evaluate=False, partial_sample=False,folds=5)\n",
    "\n",
    "        #FS mit Approximation des PSO\n",
    "\n",
    "        log = Evolution.PSO(dataset, options, population_size, steps_no_change=2, steps=5, topology=topology, verbose=1)\n",
    "        feature_subset = log.iloc[-1]['ind']  \n",
    "        feature_subset = np.array(feature_subset)\n",
    "\n",
    "        selected_features = list(np.where(feature_subset == 1)[0])\n",
    "        num_selected_features = len(selected_features)\n",
    "        duration = np.round(log.iloc[-1]['time'], 2)\n",
    "\n",
    "\n",
    "        dataset.set_features(selected_features)\n",
    "\n",
    "        #Regressor trainieren\n",
    "        dataset.fit_classifier()\n",
    "\n",
    "        # Cross-Validation\n",
    "        dataset.set_CV()\n",
    "        cv = dataset.get_CV()\n",
    "\n",
    "        #Validierung auf Testset\n",
    "        dataset.set_train_metrics()\n",
    "        train = dataset.get_train_metrics()\n",
    "        traintime = dataset.get_traintime()\n",
    "\n",
    "\n",
    "        dataset.set_test_metrics()\n",
    "        test = dataset.get_test_metrics()\n",
    "\n",
    "\n",
    "\n",
    "        #dataset.plot_shapley_values(\"FS_corr_\"+model_name)\n",
    "\n",
    "        results_pso[model_name] = {\n",
    "            'Model_name': model_name,\n",
    "            'CV_TrainMAE': cv['CV_TrainMAE'],\n",
    "            'CV_TrainRMSE': cv['CV_TrainRMSE'],\n",
    "            'CV_TestMAE': cv['CV_TestMAE'],\n",
    "            'CV_TestRMSE': cv['CV_TestRMSE'],\n",
    "            'CV_fit_time': cv['CV_fit_time'],\n",
    "            'CV_fit_time_ges':cv['CV_fit_time']+duration,\n",
    "            'TrainRMSE': train['TrainRMSE'],\n",
    "            'TrainMAE': train['TrainMAE'],\n",
    "            'TestRMSE': test['TestRMSE'],\n",
    "            'TestMAE': test['TestMAE'],\n",
    "            'TrainTime': traintime,\n",
    "            'TrainTime_ges': traintime+duration,\n",
    "            'Features': selected_features,\n",
    "            'Feature-Anzahl': num_selected_features,\n",
    "            'FS-Laufzeit': duration\n",
    "        }\n",
    "\n",
    "        predictions_pso[model_name] = {\n",
    "        'Model_name': model_name,\n",
    "        'y_train': dataset.get_y_train(),\n",
    "        'y_test': dataset.get_y_test(),\n",
    "        'pred_train': dataset.get_y_pred_train(),\n",
    "        'pred_test':dataset.get_y_pred_test()\n",
    "        }\n",
    "        print(f\"Finished: Model: {model_name}\")\n",
    "    \n",
    "    # Ergebnisse der aktuellen Iteration in DataFrames umwandeln\n",
    "    df_pso = pd.DataFrame(results_pso).transpose()\n",
    "    df_pso.to_csv(f'data/PSO/{iteration:02d}_FS_pso_metrics.csv', index=False)\n",
    "    \n",
    "    # Features der aktuellen Iteration speichern\n",
    "    df_features_pso = pd.DataFrame()\n",
    "    max_selected_features = max(len(results_pso[model_name]['Features']) for model_name, _ in MLA)\n",
    "    for model_name, model_instance in MLA:\n",
    "        selected_features = df.columns[results_pso[model_name]['Features']]\n",
    "        if len(selected_features) < max_selected_features:\n",
    "            selected_features = np.append(selected_features, [np.nan] * (max_selected_features - len(selected_features)))\n",
    "        df_features_pso[model_name] = selected_features\n",
    "    df_features_pso.to_csv(f'data/PSO/{iteration:02d}_FS_pso_Features.csv', index=False)\n",
    "    \n",
    "    # Predictions speichern\n",
    "    pso_data = []\n",
    "    for model_name, data in predictions_pso.items():\n",
    "        model_data = data.copy()\n",
    "        model_data.pop('Model_name')\n",
    "        for data_type, values in model_data.items():\n",
    "            for value in values:\n",
    "                pso_data.append({'Model_name': model_name, 'Data_type': data_type, 'Value': value})\n",
    "    df_pso2 = pd.DataFrame(pso_data)\n",
    "    df_pso2.to_csv(f'data/PSO/{iteration:02d}_FS_pso_predictions.csv', index=False)\n",
    "    \n",
    "    print(f\"Finished: Iteration: {iteration}\")\n",
    "\n",
    "print(\"Alle Iterationen abeschlossen und Ergebnisse gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6306b-79bf-48b2-a4e7-700be2ec355f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
